{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLIP (03): Modern Data Science\n",
    "**(Module 02:Probablistic Graphical Models )**\n",
    "\n",
    "---\n",
    "- Materials in this module include resources collected from various open-source online repositories.\n",
    "- You are free to use, but NOT allowed to change or distribute this package.\n",
    "\n",
    "Prepared by and for \n",
    "**Student Members** |\n",
    "2022 [TULIP Lab](http://www.tulip.org.au) \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to learn from data using a very simple example of tossing a coin. We will first generate some data (30% heads and 70% tails) and will try to learn the CPD of the coin using Maximum Likelihood Estimator and Bayesian Estimator with Dirichlet prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "raw_data = np.array([0] * 30 + [1] * 70) # Representing heads by 0 and tails by 1\n",
    "data = pd.DataFrame(raw_data, columns=['coin'])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Bayesian Model\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator, BayesianEstimator\n",
    "\n",
    "model = BayesianModel()\n",
    "model.add_node('coin')\n",
    "\n",
    "# Fitting the data to the model using Maximum Likelihood Estimator\n",
    "model.fit(data, estimator=MaximumLikelihoodEstimator)\n",
    "print(model.get_cpds('coin'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the data to the model using Bayesian Estimator with Dirichlet prior with equal pseudo counts.\n",
    "model.fit(data, estimator=BayesianEstimator, prior_type='dirichlet', pseudo_counts={'coin': [50, 50]})\n",
    "print(model.get_cpds('coin'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we get the results as expected. In the maximum likelihood case we got the probability just based on the data where as in the bayesian case we had a prior of $ P(H) = 0.5 $ and $ P(T) = 0.5 $, therefore with 30% heads and 70% tails in the data we got a posterior of $ P(H) = 0.4 $ and $ P(T) = 0.6 $.\n",
    "\n",
    "Similarly we can learn in case of more complex model. Let's take an example of the student model and compare the results in case of Maximum Likelihood estimator and Bayesian Estimator.\n",
    "\n",
    "## TODO: Add fig for Student example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating radom data with each variable have 2 states and equal probabilities for each state\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "raw_data = np.random.randint(low=0, high=2, size=(1000, 5))\n",
    "data = pd.DataFrame(raw_data, columns=['D', 'I', 'G', 'L', 'S'])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator, BayesianEstimator\n",
    "\n",
    "model = BayesianModel([('D', 'G'), ('I', 'G'), ('I', 'S'), ('G', 'L')])\n",
    "\n",
    "# Learing CPDs using Maximum Likelihood Estimators\n",
    "model.fit(data, estimator=MaximumLikelihoodEstimator)\n",
    "for cpd in model.get_cpds():\n",
    "    print(\"CPD of {variable}:\".format(variable=cpd.variable))\n",
    "    print(cpd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the data was randomly generated with equal probabilities for each state we can see here that all the probability values are close to 0.5 which we expected. Now coming to the Bayesian Estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning with Bayesian Estimator using dirichlet prior for each variable.\n",
    "\n",
    "pseudo_counts = {'D': [300, 700], 'I': [500, 500], 'G': [800, 200], 'L': [500, 500], 'S': [400, 600]}\n",
    "model.fit(data, estimator=BayesianEstimator, prior_type='dirichlet', pseudo_counts=pseudo_counts)\n",
    "for cpd in model.get_cpds():\n",
    "    print(\"CPD of {variable}:\".format(variable=cpd.variable))\n",
    "    print(cpd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data was randomly generated with equal probabilities for each state, the data tries to bring the posterior probabilities close to 0.5. But because of the prior we will get the values in between the prior and 0.5."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
